# IKMS Query Planner -  Query Planning & Decomposition Agent

An intelligent Multi-Agent RAG system that uses AI-powered query planning to break down complex questions into focused sub-queries for comprehensive answers. Built with Google Gemini (free tier) and Pinecone vector database.

---

## ğŸ¯  Query Planning & Decomposition

### Problem
Traditional RAG systems perform a single retrieval call with the entire user question, often missing important aspects of complex, multi-part queries.

### Solution
An intelligent **Query Planning Agent** that:
1. âœ… Analyzes question structure and complexity
2. âœ… Creates a structured search strategy
3. âœ… Decomposes complex questions into focused sub-questions
4. âœ… Performs multiple targeted retrieval calls
5. âœ… Aggregates results for comprehensive answers



---

## ğŸ—ï¸ Architecture

### Multi-Agent Pipeline
```
User Question
     â†“
ğŸ§  Planning Agent (Gemini 1.5 Flash)
     â”œâ”€ Analyzes question complexity
     â”œâ”€ Creates search strategy
     â””â”€ Generates sub-questions
     â†“
ğŸ” Retrieval Agent (Multiple Searches)
     â”œâ”€ Query 1: Original question â†’ Pinecone
     â”œâ”€ Query 2: Sub-question 1 â†’ Pinecone
     â”œâ”€ Query 3: Sub-question 2 â†’ Pinecone
     â””â”€ Query 4: Sub-question 3 â†’ Pinecone
     â†“
âœï¸ Summarization Agent 
     â””â”€ Generates comprehensive answer
     â†“
âœ… Verification Agent 
     â””â”€ Validates quality
     â†“
Final Answer
```

### Technology Stack

- **LLM**: Google Gemini 1.5 Flash (FREE tier)
- **Embeddings**: Google Gemini text-embedding-004 (FREE)
- **Vector Database**: Pinecone (Cloud)
- **Framework**: LangChain v1.0 + LangGraph
- **Backend**: FastAPI
- **Frontend**: Streamlit
- **PDF Processing**: PyMuPDF

---



## ğŸ“‹ Prerequisites

- Python 3.10+
- Google Gemini API key 
- Pinecone API key 

---

## ğŸš€ Quick Start

### 1. Clone Repository
```bash
git clone https://github.com/sahanchathurangaherath/ikms-query-planner.git
cd ikms-query-planner
```

### 2. Create Virtual Environment
```bash
# Create virtual environment
python -m venv venv

# Activate it
# Windows:
venv\Scripts\activate

# Mac/Linux:
source venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Get API Keys

#### Google Gemini API Key (FREE):
1. Go to: https://aistudio.google.com/app/apikey
2. Click "Create API Key"
3. Copy your key (starts with `AIza...`)

#### Pinecone API Key (FREE):
1. Go to: https://app.pinecone.io/
2. Sign up for free account
3. Create a new project
4. Copy your API key from "API Keys" section

#### Create Pinecone Index:
1. In Pinecone console, click "Create Index"
2. Settings:
   - **Name**: `ikms-rag`
   - **Dimensions**: `768` (for Gemini embeddings)
   - **Metric**: `cosine`
   - **Cloud**: Choose free tier
3. Click "Create Index"

### 5. Configure Environment

Create `.env` file in project root:
```bash
touch .env
```

Add your API keys:
```env
# Google Gemini API Key 
GOOGLE_API_KEY=your-gemini-api-key-here

# Pinecone Configuration 
PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_INDEX_NAME=ikms-rag
```

**âš ï¸ Important:** Never commit `.env` to Git (already in `.gitignore`)

### 6. Index Your Documents
```bash
# Create scripts directory if not exists
mkdir -p scripts

# Index a PDF (one-time setup)
python scripts/setup_pinecone.py path/to/your/document.pdf
```

**Example:**
```bash
python scripts/setup_pinecone.py documents/research_paper.pdf
```

**Output:**
```
ğŸ“„ PINECONE PDF INDEXING
PDF: documents/research_paper.pdf
ğŸ’¡ Using FREE Gemini embeddings - No cost!

âœ… Loaded 25 pages
âœ… Created 87 chunks
ğŸ”„ Indexing into Pinecone...
âœ… SUCCESS! Indexed 87 chunks

```

### 7. Start Backend
```bash
uvicorn src.app.api:app --reload
```

Backend runs at: http://localhost:8000

**API Docs**: http://localhost:8000/docs

### 8. Start Frontend

In a new terminal:
```bash
# Activate virtual environment
venv\Scripts\activate  # Windows
source venv/bin/activate  # Mac/Linux

# Start Streamlit
streamlit run frontend/app.py
```

Frontend opens at: http://localhost:8501

---

## ğŸ“¡ API Endpoints

### Health Check
```bash
GET http://localhost:8000/health
```

**Response:**
```json
{
  "status": "healthy",
  "feature": "Query Planning Agent",
  "llm_provider": "Google Gemini 1.5 Flash (FREE)",
  "embedding_provider": "Google Gemini text-embedding-004 (FREE)",
  "vector_database": "Pinecone (Cloud)",
  "total_vectors": 87
}
```

### Question Answering
```bash
POST http://localhost:8000/qa
Content-Type: application/json

{
  "question": "What are vector databases?"
}
```

**Response:**
```json
{
  "question": "What are vector databases?",
  "plan": "The question asks for a definition...",
  "sub_questions": [
    "vector database definition",
    "vector database purpose",
    "vector database features"
  ],
  "answer": "Vector databases are specialized...",
  "context": "[C1] (Page 1, source.pdf)\n..."
}
```

### Example with Python
```python
import requests

response = requests.post(
    "http://localhost:8000/qa",
    json={"question": "How do vector databases work?"}
)

result = response.json()
print(f"Plan: {result['plan']}")
print(f"Sub-questions: {result['sub_questions']}")
print(f"Answer: {result['answer']}")
```

---

## ğŸ“ Project Structure
```
ikms-query-planner/
â”œâ”€â”€ src/app/
â”‚   â”œâ”€â”€ api.py                      # FastAPI application
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ __init__.py            # Pydantic models
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ agents/
â”‚       â”‚   â”œâ”€â”€ state.py           # QAState with plan & sub_questions
â”‚       â”‚   â”œâ”€â”€ prompts.py         # Agent system prompts
â”‚       â”‚   â”œâ”€â”€ agents.py          # Agent node functions
â”‚       â”‚   â”œâ”€â”€ graph.py           # LangGraph workflow
â”‚       â”‚   â””â”€â”€ tools.py           # Retrieval tool
â”‚       â””â”€â”€ retrieval/
â”‚           â””â”€â”€ vector_store.py    # Pinecone vector store manager
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                     # Streamlit UI
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_pinecone.py          # Index PDFs into Pinecone
â”‚   â””â”€â”€ clear_pinecone.py          # Clear Pinecone index
â”‚
â”œâ”€â”€ documents/                      # Place your PDFs here
â”œâ”€â”€ .env                           # API keys (not in repo)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ¨ Using the Frontend

### 1. Ask Questions



- Type your question in the text area
- Or click an example question from the sidebar
- Click "ğŸš€ Generate Answer"

### 2. View Results in Tabs

**ğŸ“Š Overview Tab:**
- Metrics: Sub-questions generated, retrieval calls, answer length
- Final answer display

**ğŸ§  Planning Tab:**
- Search strategy/plan
- List of generated sub-questions
- Processing pipeline visualization
- Shows Feature 1's multi-query benefit

**ğŸ” Context Tab:**
- Retrieved document chunks
- Source information
- Context statistics

**ğŸ“„ Raw Data Tab:**
- Complete JSON API response

---

## ğŸ”§ Advanced Configuration

### Custom PDF Processing

**Index Multiple PDFs:**
```bash
# Put all PDFs in documents/ folder
# Then index them all
for file in documents/*.pdf; do
    python scripts/setup_pinecone.py "$file"
done
```

**Clear Pinecone Index:**
```bash
# Remove all vectors
python scripts/clear_pinecone.py
```

### Change Models

Edit `src/app/core/agents/agents.py`:
```python
# Use Gemini Pro instead of Flash (higher quality, same free tier)
planner_llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-pro",  
    temperature=0,
    convert_system_message_to_human=True
)
```

### Adjust Chunk Settings

Edit `scripts/setup_pinecone.py`:
```python
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1500,      # Increase from 1000
    chunk_overlap=300,    # Increase from 200
    separators=["\n\n", "\n", ". ", " ", ""]
)
```

### Change Ports
```bash
# Backend on different port
uvicorn src.app.api:app --port 8001 --reload

# Frontend on different port
streamlit run frontend/app.py --server.port 8502
```

---

## ğŸ§ª Testing

### Test Backend
```bash
python test_backend.py
```

### Test with curl
```bash
# Health check
curl http://localhost:8000/health

# Ask a question (Windows PowerShell)
Invoke-RestMethod -Uri "http://localhost:8000/qa" -Method POST -ContentType "application/json" -Body '{"question":"What are vector databases?"}'
```

### Test PDF Processing
```bash
python test_pdf.py documents/your_document.pdf
```

---

## ğŸ› Troubleshooting

### "Gemini API quota exceeded"
- Check your usage at: https://aistudio.google.com/
- Free tier: 1,500 requests/day
- Wait 24 hours for reset, or upgrade to paid tier

### "Pinecone index not found"
```bash
# Check your index name in .env matches Pinecone console
# Default: PINECONE_INDEX_NAME=ikms-rag
```

### "No vectors in index"
```bash
# Index a PDF first
python scripts/setup_pinecone.py documents/sample.pdf
```

### "PDF parsing errors"
```bash
# Install PyMuPDF for better PDF handling
pip install pymupdf
```

### "Module not found"
```bash
# Ensure virtual environment is activated
venv\Scripts\activate  # Windows
source venv/bin/activate  # Mac/Linux

# Reinstall dependencies
pip install -r requirements.txt
```

### "Port already in use"
```bash
# Windows - kill process on port 8000
netstat -ano | findstr :8000
taskkill /PID <PID> /F

# Mac/Linux
lsof -ti:8000 | xargs kill -9
```

---



## ğŸ“ Learning Outcomes

This project demonstrates:

1. **Multi-Agent Coordination**
   - Specialized agents with distinct roles
   - Sequential pipeline with state propagation

2. **Query Planning & Decomposition**
   - Analyzing question complexity
   - Breaking down into sub-queries
   - Strategic retrieval planning

3. **LangGraph State Management**
   - Enhanced state schema
   - State flow through nodes

4. **Vector Database Integration**
   - Semantic search with Pinecone
   - Embedding generation with Gemini

5. **Prompt Engineering**
   - System prompts for specialized agents
   - Output format control

6. **API Design**
   - RESTful endpoints with FastAPI
   - Request/response models

---

## ğŸš€ Future Enhancements

Potential improvements beyond Feature 1:

- **Feature 2**: Multi-call retrieval with message organization
- **Feature 3**: Context critic & reranker agent
- **Feature 4**: Evidence-aware answers with chunk citations
- **Feature 5**: Conversational multi-turn QA with memory
- Query history tracking
- User feedback collection
- A/B testing different planning strategies

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

---

## ğŸ“ License

MIT License - see LICENSE file for details.

---

## ğŸ‘¤ Author

**Sahan Chathuranga Herath**
- GitHub: [@sahanchathurangaherath](https://github.com/sahanchathurangaherath)
- ---

## ğŸ™ Acknowledgments

- [Google Gemini](https://ai.google.dev/) for free LLM and embeddings
- [Pinecone](https://www.pinecone.io/) for vector database
- [LangChain](https://github.com/langchain-ai/langchain) for agent framework
- [LangGraph](https://github.com/langchain-ai/langgraph) for workflow orchestration
- [FastAPI](https://fastapi.tiangolo.com/) for API framework
- [Streamlit](https://streamlit.io/) for frontend

---

## ğŸ“ Support

Having issues?

1. Check [Troubleshooting](#-troubleshooting) section
2. Review [Issues](https://github.com/sahanchathurangaherath/ikms-query-planner/issues)
3. Open new issue with:
   - Error message
   - Steps to reproduce
   - Environment details (OS, Python version)

---



*Last Updated: January 2025*
